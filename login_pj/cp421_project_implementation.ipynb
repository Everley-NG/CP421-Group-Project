{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098df237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP421 Group Project (Group 3)\n",
    "# -----------------------------------------------------------------\n",
    "# File: cp421_group_project.ipynb\n",
    "# Author: Yvonne Itangishaka, Mariam Lom, Hoi Hin Ng, Melissa Pinto\n",
    "# Due Date: Dec 6th, 2023\n",
    "# -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038c3bfa",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b9a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a95135",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac60c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Book Recommendation dataset from Kaggle\n",
    "books_data = pd.read_csv('Books.csv')\n",
    "ratings_data = pd.read_csv('Ratings.csv')\n",
    "users_data = pd.read_csv('Users.csv')\n",
    "\n",
    "print(\"Books Data:\")\n",
    "display(books_data.head())\n",
    "print(\"\\nRatings Data:\")\n",
    "display(ratings_data.head())\n",
    "print(\"\\nUsers Data:\")\n",
    "display(users_data.head())\n",
    "\n",
    "# Concatenate relevant columns into 'Books-Data'\n",
    "books_data[\"Books-Data\"] = (\n",
    "    books_data[\"ISBN\"].astype(str) +\n",
    "    books_data[\"Book-Title\"] +\n",
    "    books_data[\"Book-Author\"] +\n",
    "    books_data[\"Year-Of-Publication\"].astype(str) +\n",
    "    books_data[\"Publisher\"] +\n",
    "    books_data[\"Image-URL-S\"] +\n",
    "    books_data[\"Image-URL-M\"] +\n",
    "    books_data[\"Image-URL-L\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075fe36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data = pd.read_csv('/content/Books.csv', dtype={'Year-Of-Publication': str})\n",
    "ratings_data = pd.read_csv('/content/Ratings.csv')\n",
    "users_data = pd.read_csv('/content/Users.csv')\n",
    "\n",
    "# Concatenate relevant columns into 'Books-Data' column\n",
    "books_data[\"Books-Data\"] = (\n",
    "    books_data[\"ISBN\"].astype(str) +\n",
    "    books_data[\"Book-Title\"]+\n",
    "    books_data[\"Book-Author\"] +\n",
    "    books_data[\"Year-Of-Publication\"].astype(str) +\n",
    "    books_data[\"Publisher\"] +\n",
    "    books_data[\"Image-URL-S\"] +\n",
    "    books_data[\"Image-URL-M\"] +\n",
    "    books_data[\"Image-URL-L\"]\n",
    ")\n",
    "\n",
    "print(\"Books Data:\")\n",
    "display(books_data.head())\n",
    "print(\"\\nRatings Data:\")\n",
    "display(ratings_data.head())\n",
    "print(\"\\nUsers Data:\")\n",
    "display(users_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015b3a66",
   "metadata": {},
   "source": [
    "## Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data = books_data.drop(columns=['Image-URL-S', 'Image-URL-M', 'Image-URL-L']) #drop because it is not needed\n",
    "#Check for missing values\n",
    "missing_books = books_data.isnull().sum()\n",
    "print(\"missing values in books:\\n\",missing_books)\n",
    "print(\"\\n\")\n",
    "missing_ratings = ratings_data.isnull().sum()\n",
    "print(\"missing values in ratings:\\n\",missing_ratings)\n",
    "print(\"\\n\")\n",
    "missing_users = users_data.isnull().sum()\n",
    "print(\"missing values in users:\\n\",missing_users)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Check for duplicates in data set\n",
    "print(\"duplicates in books:\\n\",books_data.duplicated().sum())\n",
    "print(\"\\n\")\n",
    "ratings_books = ratings_data.duplicated().sum()\n",
    "print(\"duplicates in ratings:\\n\",ratings_books)\n",
    "print(\"\\n\")\n",
    "duplicate_users = users_data.duplicated().sum()\n",
    "print(\"duplicates in users:\\n\",duplicate_users)\n",
    "\n",
    "#print ((ratings_data==0).values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c08bc42",
   "metadata": {},
   "source": [
    "## Merge All Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f877b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge tables\n",
    "first_merged_data = pd.merge(books_data, ratings_data, on='ISBN', how='inner')\n",
    "merged_data = pd.merge(first_merged_data, users_data, on='User-ID', how='inner')\n",
    "\n",
    "display(merged_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e1f65",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752f5d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizations, check for any outliers!\n",
    "\n",
    "#Publication Year\n",
    "valid_years = merged_data['Year-Of-Publication'].astype(str).str.isnumeric()\n",
    "filtered_data = merged_data[valid_years]\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(filtered_data['Year-Of-Publication'].astype(int), color='skyblue', fill=True)\n",
    "plt.title('Density Plot of Books Based on Publication Year')\n",
    "plt.xlabel('Publication Year')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "#Count Plot of Books for Top 20 Publication Years\n",
    "valid_years = merged_data['Year-Of-Publication'].astype(str).str.isnumeric()\n",
    "filtered_data = merged_data[valid_years]\n",
    "top_years = filtered_data['Year-Of-Publication'].value_counts().nlargest(20).index\n",
    "filtered_data_top_years = filtered_data[filtered_data['Year-Of-Publication'].isin(top_years)]\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='Year-Of-Publication', data=filtered_data_top_years, palette='viridis')\n",
    "plt.title('Count Plot of Books for Top 20 Publication Years')\n",
    "plt.xlabel('Publication Year')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n",
    "\n",
    "# Density plot of Average book rating\n",
    "average_ratings = merged_data.groupby('ISBN')['Book-Rating'].mean()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(average_ratings, color='skyblue', fill=True)\n",
    "plt.title('Density Plot of Average Book Ratings')\n",
    "plt.xlabel('Average Rating')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "#Distribution of Book Ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(merged_data['Book-Rating'], bins=5, edgecolor='black', color='skyblue', alpha=0.7)\n",
    "overall_average_rating = merged_data['Book-Rating'].mean()\n",
    "plt.axvline(x=overall_average_rating, color='red', linestyle='dashed', linewidth=2, label=f'Overall Avg: {overall_average_rating:.2f}')\n",
    "plt.title('Distribution of Book Ratings')\n",
    "plt.xlabel('Book Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Distribution of User rating counts\n",
    "user_ratings_count = merged_data['User-ID'].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(user_ratings_count, bins=50, edgecolor='black')\n",
    "plt.title('Distribution of User Ratings')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.xlim(0, 2000)\n",
    "plt.show()\n",
    "\n",
    "#most popular locations\n",
    "merged_data['Location'] = merged_data['Location'].apply(lambda x:x.split(',')[-1])\n",
    "merged_data['Location'].value_counts().head(10).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8fe2c0",
   "metadata": {},
   "source": [
    "## Setting Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187bdf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user who has rated at least x books\n",
    "#books that have received at least x ratings ( x average ratings ?) Book ratings>=50\n",
    "#removes outliers\n",
    "merged_data = merged_data.groupby('ISBN').filter(lambda x: x['Book-Rating'].count() >= 50)\n",
    "merged_data = merged_data.groupby('User-ID').filter(lambda x: x['Book-Rating'].count() >= 50)\n",
    "\n",
    "# Display the merged_data after applying the threshold\n",
    "print(\"Merged data after applying thresholds:\")\n",
    "display(merged_data.head())\n",
    "\n",
    "print(merged_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622dd317",
   "metadata": {},
   "source": [
    "## KNN Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d088f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_user_mat = merged_data.pivot(index='ISBN', columns='User-ID', values='Book-Rating').fillna(0)\n",
    "book_user_mat_sparse = csr_matrix(book_user_mat.values)\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "model_knn.fit(book_user_mat_sparse)\n",
    "\n",
    "\n",
    "target_book_isbn = '0452264464'  # Replace with the actual ISBN\n",
    "target_book_index = book_user_mat.index.get_loc(target_book_isbn)\n",
    "distances, indices = model_knn.kneighbors([book_user_mat.iloc[target_book_index].values], n_neighbors=5)\n",
    "\n",
    "print(\"Nearest Neighbors for Book with ISBN:\", target_book_isbn)\n",
    "for i, (distance, index) in enumerate(zip(distances.flatten(), indices.flatten())):\n",
    "    neighbor_book_isbn = book_user_mat.index[index]\n",
    "    print(f\"{i + 1}. ISBN: {neighbor_book_isbn}, Distance: {distance}\")\n",
    "\n",
    "# print(\"Distances:\", distances.flatten())\n",
    "# print(\"Indices:\", indices.flatten())\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.barh(range(len(distances.flatten())), distances.flatten(), color='skyblue')\n",
    "# plt.xlabel('Distance')\n",
    "# plt.ylabel('Neighbor')\n",
    "# plt.title(f'Nearest Neighbors for Book with ISBN: {target_book_isbn}')\n",
    "# plt.yticks(range(len(indices.flatten())), [book_user_mat.index[idx] for idx in indices.flatten()])\n",
    "# plt.gca().invert_yaxis()  # Invert y-axis for better visualization\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa827d9",
   "metadata": {},
   "source": [
    "## Calculation Global Mean, User Mean, Item Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6ebae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculating global,\n",
    "\n",
    "global_mean = merged_data['Book-Rating'].mean()\n",
    "\n",
    "# Test\n",
    "print(\"Global Mean:\", global_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a4512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_means = merged_data.groupby('User-ID')['Book-Rating'].mean()\n",
    "\n",
    "# Test\n",
    "user_id = 11676  # Replace with the desired user ID\n",
    "user_mean = user_means.get(user_id, global_mean)  # Use global mean if user ID is not found\n",
    "print(f\"User {user_id} Mean Rating:\", user_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da396e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_means = merged_data.groupby('ISBN')['Book-Rating'].mean()\n",
    "\n",
    "# Test\n",
    "isbn = '0440234743'  # Replace with the desired ISBN\n",
    "item_mean = item_means.get(isbn, global_mean)  # Use global mean if ISBN is not found\n",
    "print(f\"Item {isbn} Mean Rating:\", item_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129543b",
   "metadata": {},
   "source": [
    "## Spliting data into Training/Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(merged_data, test_size=0.2, random_state=42)\n",
    "# Create user-item matrices training and testing sets\n",
    "trainset_matrix = trainset.pivot_table(index='User-ID', columns='ISBN', values='Book-Rating', fill_value=0)\n",
    "testset_matrix = testset.pivot_table(index='User-ID', columns='ISBN', values='Book-Rating', fill_value=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e2b707",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b153d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaborative based filtering\n",
    "\n",
    "class CollaborativeFilteringRecommendationSystem:\n",
    "    def __init__(self, user_Item, global_mean, user_means, item_means):\n",
    "        self.user_Item = user_Item\n",
    "        self.global_mean = global_mean\n",
    "        self.user_means = user_means\n",
    "        self.item_means = item_means\n",
    "        self.userPearsonSim = 1 - pairwise_distances(user_Item, metric='correlation')\n",
    "        self.itemPearsonSim = 1 - pairwise_distances(user_Item.T, metric='correlation')\n",
    "\n",
    "    def userBased_predict(self, user_id, item_id):\n",
    "        user_ratings = self.user_Item.loc[user_id]\n",
    "        ratingsSimValue = pd.Series(self.itemPearsonSim[self.user_Item.columns.get_loc(item_id)], index=self.user_Item.columns)\n",
    "        filter_ratingsSimValue = np.multiply(ratingsSimValue, user_ratings)\n",
    "        user_mean = self.user_means.get(user_id, self.global_mean)\n",
    "        itemUserRating_prediction = (filter_ratingsSimValue.sum() + user_mean) / (ratingsSimValue.abs().sum() + 1)\n",
    "        return itemUserRating_prediction\n",
    "\n",
    "    def itemBased_predict(self, user_id, item_id):\n",
    "        user_ratings = self.user_Item.loc[user_id]\n",
    "        ratingsSimValue = pd.Series(self.userPearsonSim[user_id - 1], index=self.user_Item.index)\n",
    "        filter_ratingsSimValue = np.multiply(ratingsSimValue, user_ratings)\n",
    "        item_mean = self.item_means.get(item_id, self.global_mean)\n",
    "        itemUserRating_prediction = (filter_ratingsSimValue.sum() + item_mean) / (ratingsSimValue.abs().sum() + 1)\n",
    "        return itemUserRating_prediction\n",
    "\n",
    "    def bookUser_Recommender(self, user_id, top_n=10):\n",
    "        itemRatings_prediction = {}\n",
    "        for item_id in self.user_Item.columns:\n",
    "            itemUserRating_prediction = self.userBased_predict(user_id, item_id)\n",
    "            itemRatings_prediction[item_id] = itemUserRating_prediction\n",
    "        bestBook_recommendations = sorted(itemRatings_prediction.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        return bestBook_recommendations\n",
    "\n",
    "\n",
    "user_item_matrix_sparse = csr_matrix(trainset_matrix.values)\n",
    "\n",
    "# Start the recommendation system with the training data and additional parameters\n",
    "recSystrain = CollaborativeFilteringRecommendationSystem(trainset_matrix, global_mean, user_means, item_means)\n",
    "\n",
    "# Get recommendations for a user from the test set\n",
    "user_id = 177458\n",
    "bestBook_recommendations = recSystrain.bookUser_Recommender(user_id)\n",
    "\n",
    "# Extract only ISBNs from the list of tuples\n",
    "isbn_Recommend = list(map(lambda x: x[0], bestBook_recommendations))\n",
    "\n",
    "# Extract book details for the best recommendations using ISBNs\n",
    "book_info = books_data.set_index('ISBN')\n",
    "recommended_books_info = book_info.loc[isbn_Recommend]\n",
    "\n",
    "# Display the best recommendations for the user\n",
    "display(recommended_books_info[['Book-Title', 'Year-Of-Publication']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649c89f",
   "metadata": {},
   "source": [
    "## CF-Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee9e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Recommendations\n",
    "user_id = 177458\n",
    "bestBook_recommendations = recSystrain.bookUser_Recommender(user_id)\n",
    "\n",
    "# Extract ISBNs and Actual Ratings\n",
    "isbn_Recommend, actual_ratings = zip(*[(isbn, testset_matrix.loc[user_id, isbn]) for isbn, _ in bestBook_recommendations])\n",
    "\n",
    "# Generate Predicted Ratings\n",
    "itemRatings_prediction = [recSystrain.userBased_predict(user_id, item_id) for item_id in isbn_Recommend]\n",
    "\n",
    "# Calculate Evaluation Metrics\n",
    "mse = mean_squared_error(actual_ratings, itemRatings_prediction)\n",
    "rmse = mean_squared_error(actual_ratings, itemRatings_prediction, squared=False)\n",
    "mae = mean_absolute_error(actual_ratings, itemRatings_prediction)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4257d8d3",
   "metadata": {},
   "source": [
    "## Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df75b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.drop_duplicates(subset='Book-Title', keep='first', inplace=True)\n",
    "\n",
    "class ContentBasedFiltering:\n",
    "    def __init__(self, trainset):\n",
    "        self.trainset = trainset\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        self.tfidf_matrix = self._create_tfidf_matrix()\n",
    "\n",
    "    def _create_tfidf_matrix(self):\n",
    "        book_text_data = self.trainset['Book-Title'].astype(str) + ' ' + self.trainset['Book-Author'].astype(str)  # Concatenate 'Book-Title' and 'Book-Author' for TF-IDF\n",
    "        tfidf_matrix = self.tfidf_vectorizer.fit_transform(book_text_data)\n",
    "        return tfidf_matrix\n",
    "\n",
    "    def recommend_similar_books(self, book_title, top_n=10):\n",
    "        book_index = self.trainset[self.trainset['Book-Title'] == book_title].index[0]\n",
    "        similarity_scores = cosine_similarity(self.tfidf_matrix, self.tfidf_matrix[book_index])\n",
    "        similar_books_indices = similarity_scores.argsort(axis=0)[::-1][1:top_n+1].flatten()\n",
    "\n",
    "        similar_books_info = self.trainset.iloc[similar_books_indices][[\"ISBN\", \"Book-Title\", \"Book-Author\", \"Year-Of-Publication\"]]\n",
    "        return similar_books_info\n",
    "\n",
    "# Perform train-test split on merged_data\n",
    "trainset, testset = train_test_split(merged_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize content-based system with trainset\n",
    "content_based_system = ContentBasedFiltering(trainset)\n",
    "\n",
    "# Get content-based recommendations for a specific book title\n",
    "book_title = \"Wild Justice\"\n",
    "bestBook_recommendations = content_based_system.recommend_similar_books(book_title)\n",
    "\n",
    "# Extract only ISBNs from the list of recommendations\n",
    "isbn_Recommend = bestBook_recommendations['ISBN'].tolist()\n",
    "\n",
    "# Extract book details for the recommended ISBNs from books_data\n",
    "book_info = books_data.set_index('ISBN')\n",
    "recommended_books_info = book_info.loc[isbn_Recommend]\n",
    "\n",
    "# Display the recommended book details\n",
    "display(recommended_books_info[['Book-Title', 'Year-Of-Publication']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78583686",
   "metadata": {},
   "source": [
    "## Hybrid Recomendation System and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f91315",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRecommender:\n",
    "    def __init__(self, collaborative_filter, content_filter, popular_items, collab_weight=8.5, content_weight=8.5):\n",
    "        self.collaborative_filter = collaborative_filter\n",
    "        self.content_filter = content_filter\n",
    "        self.popular_items = popular_items  # List of popular items as a fallback\n",
    "        self.collab_weight = collab_weight  # Weight for collaborative filtering scores\n",
    "        self.content_weight = content_weight  # Weight for content-based filtering scores\n",
    "\n",
    "    def hybrid_recommendations(self, user_id, book_title, testset_matrix, top_n=10):\n",
    "        # Generate collaborative filtering recommendations\n",
    "        collab_recs = self.collaborative_filter.bookUser_Recommender(user_id)\n",
    "\n",
    "        # Generate content-based recommendations\n",
    "        content_recs = self.content_filter.recommend_similar_books(book_title)\n",
    "\n",
    "        # Normalize scores from collaborative filtering recommendations\n",
    "        collab_scores = {isbn: rating for isbn, rating in collab_recs}\n",
    "        max_collab_score = max(collab_scores.values())\n",
    "        normalized_collab_scores = {isbn: score / max_collab_score for isbn, score in collab_scores.items()}\n",
    "\n",
    "        # Normalize scores from content-based recommendations\n",
    "        content_scores = {isbn: 1 / (index + 1) for index, isbn in enumerate(content_recs['ISBN'])}\n",
    "        max_content_score = max(content_scores.values())\n",
    "        normalized_content_scores = {isbn: score / max_content_score for isbn, score in content_scores.items()}\n",
    "\n",
    "        # Combine normalized scores with weighted average\n",
    "        combined_scores = {}\n",
    "        for isbn in set(normalized_collab_scores) | set(normalized_content_scores):\n",
    "            collab_score = normalized_collab_scores.get(isbn, 0) * self.collab_weight\n",
    "            content_score = normalized_content_scores.get(isbn, 0) * self.content_weight\n",
    "            combined_scores[isbn] = collab_score + content_score\n",
    "\n",
    "        # Sort the combined recommendations by score\n",
    "        sorted_combined_recs = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:int(top_n)]\n",
    "\n",
    "        # Extract ISBNs from the combined recommendations\n",
    "        isbn_recommendations = [isbn for isbn, _ in sorted_combined_recs]\n",
    "\n",
    "        # Fallback for new users or items - Recommend popular items if no recommendations\n",
    "        if not isbn_recommendations:\n",
    "            isbn_recommendations = self.popular_items\n",
    "\n",
    "        # Extract book details for the recommended ISBNs from books_data\n",
    "        book_info = books_data.set_index('ISBN')\n",
    "        recommended_books_info = book_info.loc[isbn_recommendations]\n",
    "\n",
    "        # Evaluate performance using testset_matrix\n",
    "        user_test_ratings = testset_matrix.loc[user_id]\n",
    "        print(\"User Test Ratings:\")\n",
    "        print(user_test_ratings)\n",
    "\n",
    "        # Check if testset_matrix only contains zeros\n",
    "        print(\"Testset Matrix contains only zeros:\", user_test_ratings.eq(0).all().all())\n",
    "\n",
    "        # Print non-zero entries in user_test_ratings\n",
    "        non_zero_ratings = user_test_ratings[user_test_ratings != 0]\n",
    "        print(\"Non-Zero Ratings:\")\n",
    "        print(non_zero_ratings)\n",
    "\n",
    "        actual_ratings = user_test_ratings[user_test_ratings.index.isin(isbn_recommendations)]\n",
    "        print(\"Filtered Actual Ratings:\")\n",
    "        print(actual_ratings)\n",
    "\n",
    "        predicted_ratings = [combined_scores.get(isbn, 0) for isbn in isbn_recommendations]\n",
    "\n",
    "        # Calculate RMSE on test set\n",
    "        rmse = mean_squared_error(actual_ratings, predicted_ratings, squared=False)\n",
    "\n",
    "        # Calculate Precision, Recall, and F1-score\n",
    "        # Assuming a threshold for predicted ratings to determine relevance\n",
    "        threshold = 0.1  # Adjust as needed\n",
    "        predicted_labels = [1 if rating >= threshold else 0 for rating in predicted_ratings]\n",
    "        actual_labels = [1 if rating > 0 else 0 for rating in actual_ratings]\n",
    "\n",
    "        precision = precision_score(actual_labels, predicted_labels)\n",
    "        recall = recall_score(actual_labels, predicted_labels)\n",
    "        f1 = f1_score(actual_labels, predicted_labels)\n",
    "\n",
    "        print(\"Actual Ratings:\", actual_ratings)\n",
    "        print(\"Predicted Ratings:\", predicted_ratings)\n",
    "        print(\"Predicted Labels:\", predicted_labels)\n",
    "\n",
    "        #trial on training\n",
    "        predicted_ratings_train = [combined_scores.get(isbn, 0) for isbn in trainset_matrix.columns]\n",
    "        actual_ratings_train = trainset_matrix.loc[user_id]\n",
    "        rmse_train = mean_squared_error(actual_ratings_train, predicted_ratings_train, squared=False)\n",
    "\n",
    "        # Calculate Precision, Recall, and F1-score for the training set\n",
    "        predicted_labels_train = [1 if rating >= threshold else 0 for rating in predicted_ratings_train]\n",
    "        actual_labels_train = [1 if rating > 0 else 0 for rating in actual_ratings_train]\n",
    "\n",
    "        precision_train = precision_score(actual_labels_train, predicted_labels_train)\n",
    "        recall_train = recall_score(actual_labels_train, predicted_labels_train)\n",
    "        f1_train = f1_score(actual_labels_train, predicted_labels_train)\n",
    "\n",
    "        print(\"\\nTraining Set Metrics:\")\n",
    "        print(\"RMSE:\", rmse_train)\n",
    "        print(\"Precision:\", precision_train)\n",
    "        print(\"Recall:\", recall_train)\n",
    "        print(\"F1-score:\", f1_train)\n",
    "\n",
    "        return recommended_books_info[['Book-Title', 'Year-Of-Publication']], rmse, precision, recall, f1,rmse_train,precision_train,recall_train,f1_train\n",
    "\n",
    "collaborative_filter = CollaborativeFilteringRecommendationSystem(trainset_matrix, global_mean, user_means, item_means)\n",
    "\n",
    "content_filter = ContentBasedFiltering(trainset)\n",
    "\n",
    "# List of popular items as a fallback (Books with ratings of 10)\n",
    "popular_items = [\n",
    "    '3596151465',\n",
    "    '055310666X',\n",
    "    '60096195',\n",
    "    '142302198',\n",
    "    '038076041X',\n",
    "    '699854289',\n",
    "    '786817070',\n",
    "    '805057706',\n",
    "    '1573248533',\n",
    "    '3423071516'\n",
    "]\n",
    "\n",
    "# Initialize the hybrid recommender system with both filters and popular items\n",
    "hybrid_recommender = HybridRecommender(collaborative_filter, content_filter, popular_items)\n",
    "\n",
    "# Get hybrid recommendations for a specific user and book title\n",
    "user_id = 177458\n",
    "book_title = \"Wild Justice\"\n",
    "# recommended_books, rmse, precision, recall, f1 = hybrid_recommender.hybrid_recommendations(user_id, book_title, testset_matrix)\n",
    "recommended_books, rmse, precision, recall, f1,rmse_train,precision_train,recall_train,f1_train = hybrid_recommender.hybrid_recommendations(user_id, book_title, trainset_matrix)\n",
    "\n",
    "# Display the hybrid recommendations and performance metrics\n",
    "#test set\n",
    "print(\"Recommended Books:\")\n",
    "display(recommended_books)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "#overfitting\n",
    "print(\"\\nTraining Set Metrics:\")\n",
    "print(\"RMSE:\", rmse_train)\n",
    "print(\"Precision:\", precision_train)\n",
    "print(\"Recall:\", recall_train)\n",
    "print(\"F1-score:\", f1_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
